
\section{Conclusion}

The ultimate goal in developing artificial agents that act
intelligently in multi-agent scenarios is to apply them to real-world
problems.  To a limited extent, this goal has already been achieved:
artificial agents interact with humans in the stock market and in
online advertising auctions, for example.  But before we can
successfully expand the scope of applications where multi-agent
learning can be applied in the real world, a deeper understanding of
how artificial agents interact with humans is required.

One major goal in the development of artificial agents is for them to
solve tasks in collaboration with human agents.  Given the
controversial nature of rationality assumptions as they apply to
humans~\cite{kahnemanst82}, an artificial agent that plans its
collaboration by assuming the humans in its environment will act
rationally is unlikely to be successful in its collaborations.
Instead of rationality as the underlying principle guiding human
behavior, this proposal is grounded in the assumption that humans
abide by norms.



