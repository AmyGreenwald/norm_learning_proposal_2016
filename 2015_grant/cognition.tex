
\section{}

% I am using the "machine" language throughout because that's how Reza
% has framed the problem.  I could see, however, swapping "robot" for
% "machine" if you all prefer that.

Human-machine collaboration will never be achieved at scale unless our
machines can be counted on to regularly engage in productive social
interactions with us.  Working towards the ultimate goal of machines
as our partners, we propose to focus on one fundamental driver of
social interactions: \textbf{social norms}.  We claim that we cannot
we make progress toward designing machines that are genuine
partners---machines that learn from and teach humans, help and
collaborate with humans, and are safe and effective---unless we make
progress toward understanding how humans represent and learn norms.%
\footnote{Note that our objective is not strong AI; rather, a machine
  cannot be equipped with the requisite model of social cognition if
  it does not first have a model of human social cognition.}

% JLA: "CwC DARPA call didn't really address non-linguistic human-machine  interactions and if we had some research saying that a large portion of human-human  interactions are non-linguistic while collaborating to solve a task, that could be some  strong empirical support for our already compelling argument. 

The tremendous challenge in designing and building machines that will
someday be our partners lies in the complex dynamical system that
unfolds when two autonomous, intelligent agents interact.  In the case
of human-human interaction, at least four streams of processes unfold:
(a) a vast number of mental states (goals, beliefs, desires, emotions,
etc.) in one person co-exist and change in parallel with a vast number
of mental states in the other person; (b) each person has a
substantial number of metarepresentations (e.g., $P_1$'s belief that
$P_2$ wants a screwdriver) and at least a modest number of
meta-metarepresentations (e.g., $P_1$'s belief that $P_2$ thinks that
$P_1$ knows where a screwdriver is); (c) the partners observe and/or
communicate with one another, which demands ongoing real-time updating
of these representations; and (d) each person's actions must fully
take into account all of the above processes.

Unravelling the aforementioned dynamic processes presents enormous
challenges, some of which researchers are beginning to
tackle~\cite{williams_robot_2012,cangelosi_2015}.  In short, what is
required is to advance machine capabilities to instantiate rich,
dynamic representations of a collaboration partner's mental states and
actions---i.e., a machine's {\bf own social cognition}---and, as part
of this capability, models of the human partner's own representations
of the collaboration partner---i.e., a rich computational {\bf model
  of human social cognition}.\commenta{is this backwards!!??}  But
success in this transformative endeavor requires, we argue, one
determinant of dynamic social interaction that has been almost
entirely overlooked in the AI community: social norms.

\comment{
As important as it is for a machine to have its own mechanisms of
social cognition and to have an adequate model of human social
cognition, such a machine would still not be an safe, effective,
and trustworthy partner for humans.  This is because a fundamental
element would be missing that uniquely characterizes human social life: 
the powerful influence of (omnipresent) social norms.
}

Norms guide and constrain every cultural behavior, from eating and
dressing to speaking and working. More importantly, humans expect one
another to grasp and abide by a dizzying number of norms.  In fact,
failure to follow some norms can result in disastrous consequences
(e.g., a British tourist driving on the left side of the road in
America). If humans interact with machines in genuinely collaborative
situations, they will expect those machines to similarly grasp and
abide by the relevant social norms.

In sum, the present project takes a first step toward cognitive and
social foundations of human--machine collaboration by focusing on the
normative context in which such collaboration is inevitably embedded.
In particular, we will pursue {\bf three aims}:

\begin{enumerate}
%[label=\bfseries Aim \arabic*:, leftmargin=*, align=left]

\item Conducting innovative scientific experiments to reveal and
  formalize the properties and underlying cognitive processes of 
  ``the human norm system.''\commenta{???}

\item Developing conceptual and computational formalisms required for
  equipping artificial agents with a norm system.

\item Providing a proof of concept that computational algorithms can
  learn norms in human-machine and machine-machine settings.

\end{enumerate}

\textbf{
This project feeds into the broad vision of building machines as
partners, which requires that machines that have both their own
mechanisms of social cognition and a model of human social cognition.
%---for norm capacity is a core component of social cognition.  
By acquiring a norm capacity, machines thereby acquire a key component
of their cognitive abilities; and by acquiring a model of human norm
capacity, machines thereby acquire a key component of their model of
human social cognition.}

