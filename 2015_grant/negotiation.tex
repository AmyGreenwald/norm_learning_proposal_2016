\documentclass[12pt]{article}
\usepackage{cite}
\begin{document}


Our proposed work is situated to contribute to previous work in automated negotiation. The types of games we propose can be described as single issue negotiation. Viewed as a, potentially abstract, negotiation on game outcomes, our games have a small negotiation set and well defined protocol. The agents, both human and automated, have open, private strategies. That is, the strategy of the agents are hidden from each other, but their decisions are visible to all others. 

Previous work in this area that is closest to ours has studied a game called Colored Trails (CT) \cite{Grosz:2004kt}. The game board consists of a grid of colored squares, including starting cells and goal cells for each agent. At the start of a game, each agent is given a set of tiles whose colors correspond to those of the game board. The agents must use the tiles to move along a path toward the goal cell from their respective starting cells. In order to facilitate this objective, one of the two agents is allowed to propose a trade to the other agent. The second can either accept the trade or not, but is not allowed to make counter offers. There are potentially many variations on this game that incorporate different rules for the negotiation phases, scoring functions, or the amount of information shared.

This game was used to create the first artificial agent who learns social preferences through repeated observation of human play \cite{Gal:2004ua}. In their setup, all tiles are visible to both players. There is one round of negotiation before players move, so if no deal is made, then the players must do the best they can with their original tiles. By estimating weights humans place on certain parameters that influence their notions of self interest, social welfare, and inequity aversion, they are able to create an agent which outperforms humans in making offers both to humans and to other other artificial agents. Their experimental data came from a relatively small set of games, however. This work was later extended to a repeated games version of CT \cite{Gal:2007tl}. Their work here incorporates reciprocity effects in their agent's model. The agent considers both the effect past actions may have had on the present interaction (retrospection) as well as what the present decision may do to effect future interactions (prospection). They found that limiting agents to just prospective or retrospective reasoning was as effective as using both. However, it was clear that reciprocity in general was largely playing a role.

In 2013, Peled et al.\ look at a repeated revelation and negotiation version of this game where in each round, both agents choose to reveal some subset of their private tiles, then one takes a turn proposing a trade \cite{Peled:2013ug}. They show that their agent could effectively make offers to help its partners without hurting itself. Additionally, it revealed information in an intelligent way, to gain the most benefit. When this agent played humans, the humans scored better than they had against other humans or different artificial agents. That is, the agent not only played well for itself, but it played in a way to help others achieve a good score also. Later, they analyzed agent and human strategies in revelation games more deeply \cite{Peled:2015if}. They found humans follow equilibria when revealing information but not when bargaining for tiles, which makes designing agents more difficult. Relevant to our work, they illustrated the necessity to take outside information into account when moving from one-shot to repeated negotiations if the agent is interacting with humans.

The structure of our proposed games, differs from CT significantly, though. For example, some of the CT games mentioned above have randomness incorporated in the starting and goal positions or in the tile distribution. This can create an unfair advantage or an uninteresting game in some scenarios, i.e.\ a game where one player can successfully reach the goal without any trading. Contrastingly, our games have a set structure for each board. While many of them are completely symmetric, even the asymmetric games give some power to each player in determining the outcome. It is always the case that either player can force a stalemate. 

That being said, the ideas of information revelation and negotiation translate in an interesting way into our grid games. The physical moves in the grid game world can be viewed as a negotiation between agents to seek an agreement on who is allowed to reach their goal. Many of the games are constructed so that an agent can follow a particular cooperative pattern for multiple turns while still having the chance the defend, should the other agent defect. The interesting thing about our setup is that the agents are negotiating on a very small set, but in a potentially complex way. That is, the agents negotiate on accomplishing one of four outcomes that describe who is allowed to make it to their respective goal. Since we do not allow communication though, the agents must convey their preferences for these outcomes through their moves in the grid world. Additionally, the way in which these agents act in each game serves as a form of information revelation. By moving along certain paths, it is possible for the agent to convey to their intentions of cooperation, defection, or in some cases a lack of understanding about the game.


\bibliography{negotiationBib}{}
\end{document}
